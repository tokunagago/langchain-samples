# -*- coding: utf-8 -*-
"""chains.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bOLlV0vR2-TqW7m7W6Sl2-EDP_Fh5Wy_
"""

# !pip install langchain==0.0.292
# !pip install openai==0.28
import os

os.environ["OPENAI_API_KEY"] = "XXXXXXX"

from langchain.chat_models import ChatOpenAI
from langchain.output_parsers import PydanticOutputParser
from langchain.prompts import PromptTemplate
from pydantic import BaseModel, Field


class Recipe(BaseModel):
    ingredients: list[str] = Field(description="ingredients of the dish")
    steps: list[str] = Field(description="steps to make the dish")

# OutputParser
output_parser = PydanticOutputParser(pydantic_object=Recipe)

template = """料理のレシピを教えてください。

{format_instructions}

料理名：{dish}
"""

# PromptTemplate
prompt = PromptTemplate(
    template=template,
    input_variables=["dish"],
    partial_variables={"format_instructions": output_parser.get_format_instructions()}
)

# Language model
chat = ChatOpenAI(
    model_name="gpt-4o-mini",
    temperature=0,
)

from langchain import LLMChain

chain = LLMChain(prompt=prompt, llm=chat, output_parser=output_parser)
recipe = chain.run(dish="カレー")
print(recipe)
# print(type(recipe))

chat = ChatOpenAI(
    model_name="gpt-4o-mini",
    temperature=0,
)

cot_template = """以下の質問に回答してください

質問: {question}

ステップバイステップで考えましょう
"""

cot_prompt = PromptTemplate(
    input_variables=["question"],
    template=cot_template
)

cot_chain = LLMChain(llm=chat, prompt=cot_prompt)

summarize_template = """以下の文章を結論だけ一言に要約してください。

{input}
"""

summarize_propt = PromptTemplate(
    input_variables=["input"],
    template=summarize_template
)

summarize_chain = LLMChain(llm=chat, prompt=summarize_propt)

# 2つのChainをつなげたChainを作成して実行

from langchain.chains import SimpleSequentialChain

cot_summarize_chain = SimpleSequentialChain(chains=[cot_chain, summarize_chain])

result = cot_summarize_chain("私は市場に行って10個のりんごを買いました。隣人に２つ、修理工に２つ渡しました。それから５つのりんごを買って１つ食べました。りんごの残りは何個ですか？")
print(result)